---
title: AboutMe
sections:
  - type: hero_section
    title: Work Experience
    subtitle: ''
    align: center
  - type: features_section
    features:
      - title: Machine Learning Engineer
        content: >
          • Designing an in-house neural network to generate the optimal path
          for the car, based on its location, the presence of other traffic
          elements and their movements around the car as a member of a
          four-person team


          • Implemented and enhanced a neural-network based methodology to
          predict the trajectories of the adjacent vehicles for a self-driving
          car


          • Implemented and integrated a Lidar and camera-based models for
          detecting and tracking objects


          • Devised sections of motion planning algorithm to enable the car to
          incorporate the behaviors of surrounding traffic elements when making
          driving decisions


          • Finetuned networks to classify pedestrian behaviors in urban areas
          to improve the experience in the car when passing near sidewalks
          and/or crosswalks


          • Demonstrated Imagry's self-driving car to clients numerous times
          over the period of last 2 years


          • Assisted in building infrastructure for data collection and training
          deep learning networks


          • Performed benchmark testing in the lab as well as on the autonomous
          car platform and produce documentations
        align: left
        image: images/imagry0.jpeg
        image_alt: Feature 1 placeholder image
        image_position: right
        actions: []
      - title: Research Assistant
        content: >
          • Customized deep learning algorithms on GPU to improve image feature
          extraction from ImageNet dataset. Additionally, this improved image
          classification for ‘Visual Question and Answering: VQA’, an image +
          language-based AI application  


          • Improvised algorithms associated with deeper Long Short-Term Memory
          (LSTM) units in TensorFlow to improve the textual feature extraction
          for VQA application 


          • Attained accuracies of 54% and 51% for the VQA task with 25% and 1%
          measurement rates of VQA v1.0 images, respectively 


          • Analysed methodologies to minimize the relative error in predictions
          (predicting dog instead of van, for a cat) for VQA task
        align: left
        image: images/cropped-gml.png
        image_alt: Feature 2 placeholder image
        image_position: left
        actions: []
      - title: Data Scientist
        content: >
          • Designed a completely automated tool to slash the average count of
          daily errors by over 75% at Error Review Workstation (ERW) by
          prioritizing the errors encountered in real-time 


          • Implemented text analysis of different surveys for an insurance
          client to understand the satisfaction and pain points of agencies and
          customer


          • Forecasted monthly response rates at invite mix level using multiple
          forecasting techniques including ARIMA, top-down and bottom-up
          approaches to help the client devise their strategies for agencies 


          • Performed a comparative analysis of shopping study of the client and
          its competitors at different stages of purchase funnel to identify the
          scope of improvement at various stages of the funnel
        align: left
        image: images/mu_sigma.jpeg
        image_alt: Feature 3 placeholder image
        image_position: right
        actions: []
  - title: Projects
    features:
      - title: RoboHelper
        content: >
          • Implemented facial recognition security features that allow only
          certified users to control the Turtlebot


          • Executed autonomous movement of Turtlebot using SLAM and
          alternatively configured manual movements using hand gestures through
          LEAP Motion camera in ROS


          • Implemented basic object recognition module to notify owners for
          in-stock and out-of-stock items
        align: left
        image_alt: lorem-ipsum
        image_position: left
        actions:
          - label: Full Report
            url: >-
              https://github.com/anik-jha/course_projects/blob/master/CSE591_Perception_in_Robotics_Report.pdf
            style: link
            new_window: false
            no_follow: false
            type: action
        type: feature
      - title: 'Musical Expressions: Synthesizing Music from Facial Expressions'
        content: >
          • Built an experiential system to create emotional awareness, of a
          given person, by harnessing his/her facial expressions  


          • Generated distinguished audio feedback based on the class of
          expressions to create the emotional awareness
        align: left
        image_alt: lorem-ipsum
        image_position: left
        actions:
          - label: Full Report
            url: >-
              https://github.com/anik-jha/course_projects/blob/master/AME520_Understanding_Activity_Report.pdf
            style: link
            new_window: false
            no_follow: false
            type: action
        type: feature
    type: features_section
  - title: Publications
    features: []
    type: features_section
  - title: Honors and Awards
    features: []
    type: features_section
  - title: lorem-ipsum
    features: []
    type: features_section
template: advanced
---
